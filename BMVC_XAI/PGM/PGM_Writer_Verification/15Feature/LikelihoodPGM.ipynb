{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianModel\n",
    "import networkx as nx\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import networkx as nx\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "mapping_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    features = pd.read_csv('15features.csv')\n",
    "    training_pairs = pd.read_csv('seen-dataset/dataset_seen_training_siamese.csv')\n",
    "    validation_pairs = pd.read_csv('seen-dataset/dataset_seen_validation_siamese.csv')\n",
    "    training_features_pairs_info = pd.merge(training_pairs,features,left_on='left',right_on='imagename')\n",
    "    training_features_pairs_info = pd.merge(training_features_pairs_info,\n",
    "                                            features,left_on='right',\n",
    "                                            right_on='imagename', \n",
    "                                            suffixes=('1', '2'))\n",
    "    training_features_pairs_info = training_features_pairs_info.drop(training_features_pairs_info.columns[[0,4,20]],\n",
    "                                                                     axis=1)\n",
    "    training_features_pairs = training_features_pairs_info.drop(training_features_pairs_info.columns[[0,1]],\n",
    "                                                           axis=1)\n",
    "\n",
    "    validation_features_pairs_info = pd.merge(validation_pairs,features,left_on='left',right_on='imagename')\n",
    "    validation_features_pairs_info = pd.merge(validation_features_pairs_info,features,\n",
    "                                              left_on='right',\n",
    "                                              right_on='imagename', \n",
    "                                              suffixes=('1', '2'))\n",
    "    validation_features_pairs_info = validation_features_pairs_info.drop(validation_features_pairs_info.columns[[0,4,20]],\n",
    "                                                                         axis=1)\n",
    "    validation_features_pairs = validation_features_pairs_info.drop(validation_features_pairs_info.columns[[0,1]],axis=1)\n",
    "\n",
    "    training_features_pairs.to_csv('training_features.csv')\n",
    "    \n",
    "def create_categorical_distance_data():\n",
    "    feature_names = ['pen_pressure', \n",
    "                    'letter_spacing', \n",
    "                    'size', \n",
    "                    'dimension',\n",
    "                    'is_lowercase', \n",
    "                    'is_continuous', \n",
    "                    'slantness', \n",
    "                    'tilt',\n",
    "                    'entry_stroke_a', \n",
    "                    'staff_of_a', \n",
    "                    'formation_n', \n",
    "                    'staff_of_d',\n",
    "                    'exit_stroke_d', \n",
    "                    'word_formation', \n",
    "                    'constancy']\n",
    "\n",
    "    categories_dictionary = {}\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(0,4):\n",
    "        for j in range(0,4):\n",
    "            category_key     = str(i) + str(j)\n",
    "            category_key_rev = str(j) + str(i)\n",
    "            if category_key_rev in categories_dictionary.keys():\n",
    "                category_value = categories_dictionary[category_key_rev]\n",
    "            else:\n",
    "                counter += 1\n",
    "                category_value = counter\n",
    "            categories_dictionary[category_key] = category_value\n",
    "\n",
    "    categorical_data = {}\n",
    "    categorical_data['left'] = []\n",
    "    categorical_data['right'] = []\n",
    "    for feature_name in feature_names:\n",
    "        categorical_data[feature_name] = []\n",
    "    categorical_data['label'] = []\n",
    "\n",
    "    for index,row in tqdm(validation_features_pairs_info.iterrows()):\n",
    "        categorical_data['left'].append(row['left'])\n",
    "        categorical_data['right'].append(row['right'])\n",
    "        for feature_name in feature_names:\n",
    "            image1_feat = int(row[feature_name + '1']) - 1\n",
    "            image2_feat = int(row[feature_name + '2']) - 1\n",
    "            category_key = str(image1_feat)+str(image2_feat)\n",
    "            category_value = categories_dictionary[category_key]\n",
    "            categorical_data[feature_name].append(category_value)\n",
    "        categorical_data['label'].append(row['label'])\n",
    "\n",
    "    categorical_df = pd.DataFrame(categorical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_two_dataset():\n",
    "    feature_names = ['pen_pressure', \n",
    "                    'letter_spacing', \n",
    "                    'size', \n",
    "                    'dimension',\n",
    "                    'is_lowercase', \n",
    "                    'is_continuous', \n",
    "                    'slantness', \n",
    "                    'tilt',\n",
    "                    'entry_stroke_a', \n",
    "                    'staff_of_a', \n",
    "                    'formation_n', \n",
    "                    'staff_of_d',\n",
    "                    'exit_stroke_d', \n",
    "                    'word_formation', \n",
    "                    'constancy']\n",
    "    categorical_df = pd.read_csv('categorical_training_seen.csv')\n",
    "\n",
    "    for feature_name in feature_names:\n",
    "        s1 = np.unique(np.array(list(categorical_df[categorical_df['label'] == 1][feature_name].values)))\n",
    "        s0 = np.unique(np.array(list(categorical_df[categorical_df['label'] == 0][feature_name].values)))\n",
    "        mapper_dict = {}\n",
    "        for i, category in enumerate(s1):\n",
    "            mapper_dict[category] = i\n",
    "        mapping_dict[feature_name] = mapper_dict\n",
    "\n",
    "    data_label_0 = categorical_df[categorical_df['label'] == 0].drop(['Unnamed: 0','left','right','label'],axis=1)\n",
    "    data_label_1 = categorical_df[categorical_df['label'] == 1].drop(['Unnamed: 0','left','right','label'],axis=1)\n",
    "    return ((data_label_0), (data_label_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bn(data):\n",
    "    dist_model = BayesianModel([('pen_pressure','size'),\n",
    "                        ('letter_spacing', 'size'),\n",
    "                        ('dimension', 'size'),\n",
    "                        ('size', 'constancy'),\n",
    "                        ('constancy', 'word_formation'),\n",
    "                        ('word_formation', 'formation_n'),\n",
    "                        ('entry_stroke_a', 'exit_stroke_d'),\n",
    "                        ('is_lowercase', 'is_continuous'),\n",
    "                        ('staff_of_a', 'staff_of_d'),\n",
    "                        ('slantness', 'tilt')])\n",
    "    options = {\n",
    "    'node_color': 'black',\n",
    "    'node_size': 1000,\n",
    "    'width': 3,\n",
    "    'with_labels':True,\n",
    "    'font_color':'white',\n",
    "    'font_size':13\n",
    "    }\n",
    "#     nx.draw(dist_model, **options)\n",
    "    dist_model.fit(data)\n",
    "    return dist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cpd(model):\n",
    "    cpd_dict = {}\n",
    "    for cpd in model.get_cpds():\n",
    "        cpd_dict[cpd.variables[0]] = cpd\n",
    "    return cpd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_prob(cpd, col):\n",
    "    p = 1\n",
    "    for feature_name in feature_names:\n",
    "        if(feature_name == 'is_lowercase'):\n",
    "            p = p*cpd['is_lowercase'].values[mapping_dict['is_lowercase'][col['is_lowercase']]]\n",
    "        if(feature_name == 'is_continuous'):\n",
    "            p = p*cpd['is_continuous'].values[mapping_dict['is_continuous'][col['is_continuous']]][mapping_dict['is_lowercase'][col['is_lowercase']]]\n",
    "        if(feature_name == 'entry_stroke_a'):\n",
    "            p = p*cpd['entry_stroke_a'].values[mapping_dict['entry_stroke_a'][col['entry_stroke_a']]]\n",
    "        if(feature_name == 'exit_stroke_d'):\n",
    "            p = p*cpd['exit_stroke_d'].values[mapping_dict['exit_stroke_d'][col['exit_stroke_d']]][mapping_dict['entry_stroke_a'][col['entry_stroke_a']]]\n",
    "        if(feature_name == 'pen_pressure'):\n",
    "            p = p*cpd['pen_pressure'].values[mapping_dict['pen_pressure'][col['pen_pressure']]]\n",
    "        if(feature_name == 'letter_spacing'):\n",
    "            p = p*cpd['letter_spacing'].values[mapping_dict['letter_spacing'][col['letter_spacing']]]\n",
    "        if(feature_name == 'dimension'):\n",
    "            p = p*cpd['dimension'].values[mapping_dict['dimension'][col['dimension']]]\n",
    "        if(feature_name == 'size'):\n",
    "            p = p*cpd['size'].values[mapping_dict['size'][col['size']]][mapping_dict['dimension'][col['dimension']]][mapping_dict['letter_spacing'][col['letter_spacing']]][mapping_dict['pen_pressure'][col['pen_pressure']]]\n",
    "        if(feature_name == 'constancy'):\n",
    "            p = p*cpd['constancy'].values[mapping_dict['constancy'][col['constancy']]][mapping_dict['size'][col['size']]]\n",
    "        if(feature_name == 'word_formation'):\n",
    "            p = p*cpd['word_formation'].values[mapping_dict['word_formation'][col['word_formation']]][mapping_dict['constancy'][col['constancy']]]\n",
    "        if(feature_name == 'formation_n'):\n",
    "            p = p*cpd['formation_n'].values[mapping_dict['formation_n'][col['formation_n']]][mapping_dict['word_formation'][col['word_formation']]]\n",
    "        if(feature_name == 'staff_of_a'):\n",
    "            p = p*cpd['staff_of_a'].values[mapping_dict['staff_of_a'][col['staff_of_a']]]\n",
    "        if(feature_name == 'staff_of_d'):\n",
    "            p = p*cpd['staff_of_d'].values[mapping_dict['staff_of_d'][col['staff_of_d']]][mapping_dict['staff_of_a'][col['staff_of_a']]]\n",
    "        if(feature_name == 'slantness'):\n",
    "            p = p*cpd['slantness'].values[mapping_dict['slantness'][col['slantness']]]\n",
    "        if(feature_name == 'tilt'):\n",
    "            p = p*cpd['tilt'].values[mapping_dict['tilt'][col['tilt']]][mapping_dict['slantness'][col['slantness']]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "((data_label_0, data_label_1)) = create_two_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_model_label_0 = create_bn(data_label_0)\n",
    "dist_model_label_1 = create_bn(data_label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_dict_label_0 = create_cpd(dist_model_label_0)\n",
    "cpd_dict_label_1 = create_cpd(dist_model_label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_test_df = pd.read_csv('categorical_validation_seen.csv')\n",
    "\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "for i, col in categorical_test_df.iterrows():\n",
    "    \n",
    "    # Evaluating Joint Probability distribution for \n",
    "    jp_l0 = joint_prob(cpd_dict_label_0, col)\n",
    "    jp_l1 = joint_prob(cpd_dict_label_1, col)\n",
    "    \n",
    "    # Likelihood Ratio calculation\n",
    "    if(jp_l0/jp_l1 > 0):\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    \n",
    "    # Creating confusion matrix\n",
    "    if(pred == 1 and col['label'] == 1):\n",
    "        true_positives += 1\n",
    "    elif(pred == 0 and col['label'] == 0):\n",
    "        true_negatives += 1\n",
    "    elif pred == 0 and col['label'] == 1:\n",
    "        false_positives += 1\n",
    "    elif pred == 1 and col['label'] == 0:\n",
    "        false_negatives += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on seen validation set is:   0.8515358361774744\n",
      "Precision on seen validation set is:  0.9497907949790795\n",
      "Recall on seen validation set is:     0.7516556291390728\n",
      "F1 Score on seen validation set is:   0.8391866913123843\n"
     ]
    }
   ],
   "source": [
    "accuracy = (true_positives+true_negatives)/categorical_test_df.shape[0]\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "f1 = 2 * (precision*recall) / (precision+recall)\n",
    "\n",
    "print(\"Accuracy on seen validation set is:  \" , accuracy)\n",
    "print(\"Precision on seen validation set is: \" , precision)\n",
    "print(\"Recall on seen validation set is:    \" , recall)\n",
    "print(\"F1 Score on seen validation set is:  \" , f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

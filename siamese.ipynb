{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as ocr\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, Dense,MaxPooling2D, Dropout, Flatten\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "set_session(tf.Session(config=config))\n",
    "input_shape  = (64,64,1)\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3),activation='sigmoid',input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(128, (3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(256, (1, 1), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(2, (1, 1), activation='sigmoid'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "    #               optimizer = keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(model1, model2, y, margin):\n",
    "    with tf.name_scope(\"contrastive-loss\"):\n",
    "        d = tf.sqrt(tf.reduce_sum(tf.pow(model1-model2, 2), 1, keep_dims=True))\n",
    "        tmp= y * tf.square(d)    \n",
    "        tmp2 = (1 - y) * tf.square(tf.maximum((margin - d),0))\n",
    "        return tf.reduce_mean(tmp + tmp2) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 3, 3, 2)           66        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 1, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 9,634\n",
      "Trainable params: 9,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8923 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "img = ocr.imread('data/TrainingSet/0007a_num3.png', 0)\n",
    "img = (255.01 - img)/255\n",
    "x = img.reshape(-1,64,64,1)\n",
    "y = 1\n",
    "y = keras.utils.to_categorical(y)\n",
    "y = y.reshape(1,2)\n",
    "print(y)\n",
    "leftModel = model()\n",
    "leftModel.summary()\n",
    "hist = leftModel.fit(x, y, epochs = 1, verbose = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dim = 64\n",
    "l_  = tf.placeholder(tf.float32, [dim,dim,1], name='left')\n",
    "r_  = tf.placeholder(tf.float32, [dim], name='right')\n",
    "\n",
    "model.layers[0].output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 60, 60)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = leftModel.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in leftModel.layers]          # all layer outputs\n",
    "functors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "# Testing\n",
    "img1 = ocr.imread('data/TrainingSet/0002a_num3.png', 0)\n",
    "\n",
    "img1 = (255.01 - img1)/255\n",
    "# ocr.imshow('image',img1)\n",
    "# ocr.waitKey(0)\n",
    "test = img1.reshape(-1,64,64,1)\n",
    "print(test.shape)\n",
    "layer_outs = [func([test, 1.]) for func in functors]\n",
    "im = np.array(layer_outs[1][0].reshape(32,60,60))\n",
    "im.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-2c194016d349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in im:\n",
    "    ocr.imshow('img',i)\n",
    "    ocr.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59850597,  0.71027213]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = ocr.imread('data/TrainingSet/0002a_num3.png', 0)\n",
    "img1 = (255.01 - img1)/255\n",
    "x = img1.reshape(-1,64,64,1)\n",
    "leftModel.predict(img1.reshape(-1,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
